{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bac0d21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Replicação Seção 6.2 do paper:\n",
    "- GA + XGBRegressor para prever CAR_30D\n",
    "- Ranking por previsão dentro de cada trimestre\n",
    "- Moving portfolios de 100 ações (Fig. 3)\n",
    "- Portfólios por quantis (Q1–Q5)\n",
    "- Loop automático para todos os trimestres 2017–2019\n",
    "\n",
    "Pré-requisito:\n",
    "  - Diretório pead_preproc com:\n",
    "        train_processed.csv (2010–2016)\n",
    "        test_processed.csv  (2017–2019)\n",
    "\"\"\"\n",
    "\n",
    "import os, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11a6ea5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATS = [\n",
    "\n",
    "    # ===== Fundamental – níveis MET =====\n",
    "    \"RL_MET\", \"LL_MET\", \"EBITDA_MET\",\n",
    "    \"Preco_Abertura_MET\", \"Preco_Fechamento_MET\",\n",
    "    \"LPA_MET\", \"ROA_MET\", \"ROE_MET\", \"MEB_MET\",\n",
    "    \"CRESC_RL_12M_MET\", \"CRESC_LL_12M_MET\", \"CRESC_EBITDA_12M_MET\",\n",
    "    \"CAPEX_MET\", \"FCO_MET\", \"FCF_MET\",\n",
    "    \"Divida_Liquida_MET\", \"PL_MET\", \"Divida_Bruta_MET\",\n",
    "    \"AT_MET\", \"DVA_Despesas_Fin_MET\",\n",
    "    \"PC_MET\", \"PNC_MET\", \"Outros_PC_MET\",\n",
    "    \"LUB_MET\",\n",
    "\n",
    "    # ===== Fundamental – variações Q (quarter-over-quarter) =====\n",
    "    \"RL_Q_Change\", \"LL_Q_Change\", \"EBITDA_Q_Change\",\n",
    "    \"Preco_Abertura_Q_Change\", \"Preco_Fechamento_Q_Change\",\n",
    "    \"LPA_Q_Change\", \"ROA_Q_Change\", \"ROE_Q_Change\", \"MEB_Q_Change\",\n",
    "    \"CRESC_RL_12M_Q_Change\", \"CRESC_LL_12M_Q_Change\", \"CRESC_EBITDA_12M_Q_Change\",\n",
    "    \"CAPEX_Q_Change\", \"FCO_Q_Change\", \"FCF_Q_Change\",\n",
    "    \"Divida_Liquida_Q_Change\", \"PL_Q_Change\", \"Divida_Bruta_Q_Change\",\n",
    "    \"AT_Q_Change\", \"DVA_Despesas_Fin_Q_Change\",\n",
    "    \"PC_Q_Change\", \"PNC_Q_Change\", \"Outros_PC_Q_Change\",\n",
    "    \"LUB_Q_Change\",\n",
    "\n",
    "    # ===== Fundamental – variações Y (year-over-year) =====\n",
    "    \"RL_Y_Change\", \"LL_Y_Change\", \"EBITDA_Y_Change\",\n",
    "    \"Preco_Abertura_Y_Change\", \"Preco_Fechamento_Y_Change\",\n",
    "    \"LPA_Y_Change\", \"ROA_Y_Change\", \"ROE_Y_Change\", \"MEB_Y_Change\",\n",
    "    \"CRESC_RL_12M_Y_Change\", \"CRESC_LL_12M_Y_Change\", \"CRESC_EBITDA_12M_Y_Change\",\n",
    "    \"CAPEX_Y_Change\", \"FCO_Y_Change\", \"FCF_Y_Change\",\n",
    "    \"Divida_Liquida_Y_Change\", \"PL_Y_Change\", \"Divida_Bruta_Y_Change\",\n",
    "    \"AT_Y_Change\", \"DVA_Despesas_Fin_Y_Change\",\n",
    "    \"PC_Y_Change\", \"PNC_Y_Change\", \"Outros_PC_Y_Change\",\n",
    "    \"LUB_Y_Change\",\n",
    "\n",
    "    # ===== EPS Surprise Features =====\n",
    "    \"EPS_EarningsSurprise\",\n",
    "    \"EPS_Earnings_Surprise_Backward_Diff\",\n",
    "    \"EPS_Earnings_Surprise_Backward_Ave_Diff\",\n",
    "\n",
    "    # ===== Momentum & Technical Indicators =====\n",
    "    \"MA5\", \"MA50\", \"MA200\",\n",
    "    \"RSI9\", \"RSI14\", \"RSI30\",\n",
    "    \"MA5_50\", \"MA5_200\", \"MA50_200\",\n",
    "    \"MOM_1M\", \"MOM_3M\", \"MOM_6M\", \"MOM_12M\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1e26793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- CONFIGURAÇÕES --------------------\n",
    "BASE_PRE  = \"pead_preproc\"\n",
    "TRAIN_CSV = os.path.join(BASE_PRE, \"train_processed.csv\")\n",
    "TEST_CSV  = os.path.join(BASE_PRE,  \"test_processed.csv\")\n",
    "\n",
    "OUT_DIR   = \"results_6_2\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16395c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Carrega o pré-processado e cria Year/Quarter ===\n",
    "df_train = pd.read_csv(TRAIN_CSV)\n",
    "df_test  = pd.read_csv(TEST_CSV)\n",
    "df_all   = pd.concat([df_train, df_test], ignore_index=True)\n",
    "\n",
    "df_all[\"EventTradeDate\"] = pd.to_datetime(df_all[\"EventTradeDate\"])\n",
    "df_all[\"Year\"]    = df_all[\"EventTradeDate\"].dt.year\n",
    "df_all[\"Quarter\"] = df_all[\"EventTradeDate\"].dt.quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178b6fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === (opcional) GA + CV (Fig. 2) para o REGRESSOR; pode desligar com use_ga=False ===\n",
    "def ga_optimize_xgb_reg(X_train, y_train, generations=5, pop_size=10, verbose=False):\n",
    "    \"\"\"\n",
    "    GA + 5-fold CV para XGBRegressor.\n",
    "    Fitness = RMSE médio (quanto menor, melhor).\n",
    "    Compatível com versões antigas do sklearn (sem parâmetro 'squared').\n",
    "    \"\"\"\n",
    "\n",
    "    SEARCH_SPACE = {\n",
    "        \"max_depth\":        [3,4,5,6,7],\n",
    "        \"learning_rate\":    [0.01, 0.03, 0.05, 0.07, 0.1],\n",
    "        \"subsample\":        [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "        \"colsample_bytree\": [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "        \"min_child_weight\": [1,2,3,5,7],\n",
    "        \"gamma\":            [0, 0.01, 0.05, 0.1, 0.2],\n",
    "    }\n",
    "\n",
    "    def random_params():\n",
    "        return {k: np.random.choice(v) for k, v in SEARCH_SPACE.items()}\n",
    "\n",
    "    def fitness(params):\n",
    "        # KFold com embaralhamento para aproximar Fig.2 (GA + CV)\n",
    "        kf = KFold(n_splits=5, shuffle=True)\n",
    "        rmses = []\n",
    "\n",
    "        for tr, va in kf.split(X_train):\n",
    "            model = XGBRegressor(\n",
    "                n_estimators=200,\n",
    "                objective=\"reg:squarederror\",\n",
    "                **params\n",
    "            )\n",
    "            model.fit(X_train[tr], y_train[tr])\n",
    "            pred = model.predict(X_train[va])\n",
    "            # Versões antigas do sklearn não aceitam 'squared'; calculamos RMSE manualmente\n",
    "            mse  = mean_squared_error(y_train[va], pred)\n",
    "            rmse = np.sqrt(mse)\n",
    "            rmses.append(rmse)\n",
    "\n",
    "        return float(np.mean(rmses))  # menor é melhor\n",
    "\n",
    "    # População inicial\n",
    "    population = [random_params() for _ in range(pop_size)]\n",
    "\n",
    "    for gen in range(generations):\n",
    "        if verbose:\n",
    "            print(f\"[GA-REG] geração {gen+1}/{generations}\", flush=True)\n",
    "\n",
    "        scores = [fitness(p) for p in population]                 # RMSEs\n",
    "        ranked = sorted(zip(scores, population), key=lambda x: x[0])\n",
    "        survivors = [p for _, p in ranked[:pop_size // 2]]        # menores RMSE\n",
    "\n",
    "        # Reprodução + mutação segura (mantém limites válidos do XGBoost)\n",
    "        children = []\n",
    "        while len(children) < pop_size - len(survivors):\n",
    "            p1, p2 = np.random.choice(survivors, 2, replace=True)\n",
    "            child = {k: (p1[k] if np.random.rand() < 0.5 else p2[k]) for k in SEARCH_SPACE}\n",
    "            if np.random.rand() < 0.2:\n",
    "                mk = np.random.choice(list(SEARCH_SPACE.keys()))\n",
    "                child[mk] = np.random.choice(SEARCH_SPACE[mk])\n",
    "            children.append(child)\n",
    "\n",
    "        population = survivors + children\n",
    "\n",
    "    # Escolhe o melhor (menor RMSE)\n",
    "    final_scores = [fitness(p) for p in population]\n",
    "    best_params  = population[int(np.argmin(final_scores))]\n",
    "    if verbose:\n",
    "        print(\"[GA-REG] melhor RMSE:\", min(final_scores))\n",
    "        print(\"[GA-REG] best_params:\", best_params)\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff54691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Função central: ranking por CAR_30D predito + gráfico com CAR_30D REAL ===\n",
    "def rank_and_plot_quarter(year, quarter, use_ga=True, save=True, show=True):\n",
    "    # Seleciona eventos do trimestre (test set daquele trimestre)\n",
    "    mask_q = (df_all[\"Year\"] == year) & (df_all[\"Quarter\"] == quarter)\n",
    "    df_q = df_all.loc[mask_q].copy()\n",
    "    if df_q.empty:\n",
    "        print(f\"[{year} Q{quarter}] Sem eventos.\")\n",
    "        return None\n",
    "\n",
    "    # Treino: tudo ANTES do início do trimestre (conforme o artigo)\n",
    "    q_start = df_q[\"EventTradeDate\"].min()\n",
    "    df_hist = df_all[df_all[\"EventTradeDate\"] < q_start].copy()\n",
    "    if df_hist.empty:\n",
    "        print(f\"[{year} Q{quarter}] Sem histórico suficiente antes do trimestre.\")\n",
    "        return None\n",
    "\n",
    "    # X, y\n",
    "    X_tr = df_hist[FEATS].to_numpy()\n",
    "    y_tr = df_hist[\"CAR_30D\"].to_numpy()\n",
    "    X_te = df_q[FEATS].to_numpy()\n",
    "\n",
    "    # Hiperparâmetros (GA + CV Fig.2, ou defaults leves para depurar)\n",
    "    if use_ga:\n",
    "        params = ga_optimize_xgb_reg(X_tr, y_tr, generations=5, pop_size=10, verbose=True)\n",
    "    else:\n",
    "        params = {\"max_depth\":5,\"learning_rate\":0.05,\"subsample\":0.8,\n",
    "                  \"colsample_bytree\":0.8,\"min_child_weight\":3,\"gamma\":0.05}\n",
    "\n",
    "    # Modelo final e predição\n",
    "    reg = XGBRegressor(n_estimators=300, objective=\"reg:squarederror\", **params)\n",
    "    reg.fit(X_tr, y_tr)\n",
    "    df_q[\"CAR_pred\"] = reg.predict(X_te)\n",
    "\n",
    "    # RANKING: ordenar por CAR_30D predito (maior → menor)\n",
    "    df_rank = df_q.sort_values(\"CAR_pred\", ascending=False).reset_index(drop=True)\n",
    "    df_rank[\"Rank\"] = np.arange(1, len(df_rank)+1)\n",
    "\n",
    "    # GRÁFICO: barras por ação (na ordem de ranking) usando CAR_30D REAL\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.bar(df_rank[\"Rank\"], df_rank[\"CAR_30D\"] * 100)  # em %\n",
    "    plt.axhline(0, color=\"black\", linewidth=1)\n",
    "    plt.title(f\"Ranking por CAR_30D predito — Exibe CAR_30D REAL | {year} Q{quarter}\", fontsize=13)\n",
    "    plt.xlabel(\"Rank (ordenado por CAR_30D predito)\", fontsize=10)\n",
    "    plt.ylabel(\"CAR_30D REAL (%)\", fontsize=10)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # salvar/mostrar\n",
    "    if save:\n",
    "        csv_path = os.path.join(OUT_DIR, f\"ranking_{year}_Q{quarter}.csv\")\n",
    "        png_path = os.path.join(OUT_DIR, f\"ranking_{year}_Q{quarter}.png\")\n",
    "        df_rank.to_csv(csv_path, index=False)\n",
    "        plt.savefig(png_path, dpi=150)\n",
    "        print(\"Salvos:\", csv_path, \"e\", png_path)\n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()\n",
    "\n",
    "    return df_rank\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507a8391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Um trimestre específico (ex.: 2018 Q4)\n",
    "rank_and_plot_quarter(2017, 2, use_ga=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "500c2ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GA-REG] geração 1/5\n",
      "[GA-REG] geração 2/5\n",
      "[GA-REG] geração 3/5\n",
      "[GA-REG] geração 4/5\n",
      "[GA-REG] geração 5/5\n",
      "[GA-REG] melhor RMSE: 0.12884408456010188\n",
      "[GA-REG] best_params: {'max_depth': 7, 'learning_rate': 0.03, 'subsample': 0.8, 'colsample_bytree': 0.9, 'min_child_weight': 7, 'gamma': 0.01}\n",
      "Salvos: results_6_2_rank\\ranking_2017_Q1.csv e results_6_2_rank\\ranking_2017_Q1.png\n",
      "[GA-REG] geração 1/5\n",
      "[GA-REG] geração 2/5\n",
      "[GA-REG] geração 3/5\n",
      "[GA-REG] geração 4/5\n",
      "[GA-REG] geração 5/5\n",
      "[GA-REG] melhor RMSE: 0.1281543997532137\n",
      "[GA-REG] best_params: {'max_depth': 7, 'learning_rate': 0.05, 'subsample': 0.6, 'colsample_bytree': 0.7, 'min_child_weight': 1, 'gamma': 0.0}\n",
      "Salvos: results_6_2_rank\\ranking_2017_Q2.csv e results_6_2_rank\\ranking_2017_Q2.png\n",
      "[GA-REG] geração 1/5\n",
      "[GA-REG] geração 2/5\n",
      "[GA-REG] geração 3/5\n",
      "[GA-REG] geração 4/5\n",
      "[GA-REG] geração 5/5\n",
      "[GA-REG] melhor RMSE: 0.126143160123662\n",
      "[GA-REG] best_params: {'max_depth': 7, 'learning_rate': 0.03, 'subsample': 0.9, 'colsample_bytree': 1.0, 'min_child_weight': 5, 'gamma': 0.01}\n",
      "Salvos: results_6_2_rank\\ranking_2017_Q3.csv e results_6_2_rank\\ranking_2017_Q3.png\n",
      "[GA-REG] geração 1/5\n",
      "[GA-REG] geração 2/5\n",
      "[GA-REG] geração 3/5\n",
      "[GA-REG] geração 4/5\n",
      "[GA-REG] geração 5/5\n",
      "[GA-REG] melhor RMSE: 0.1269715157087814\n",
      "[GA-REG] best_params: {'max_depth': 6, 'learning_rate': 0.03, 'subsample': 0.7, 'colsample_bytree': 0.8, 'min_child_weight': 2, 'gamma': 0.01}\n",
      "Salvos: results_6_2_rank\\ranking_2017_Q4.csv e results_6_2_rank\\ranking_2017_Q4.png\n",
      "[GA-REG] geração 1/5\n",
      "[GA-REG] geração 2/5\n",
      "[GA-REG] geração 3/5\n",
      "[GA-REG] geração 4/5\n",
      "[GA-REG] geração 5/5\n",
      "[GA-REG] melhor RMSE: 0.1249087504788797\n",
      "[GA-REG] best_params: {'max_depth': 7, 'learning_rate': 0.05, 'subsample': 1.0, 'colsample_bytree': 0.8, 'min_child_weight': 5, 'gamma': 0.0}\n",
      "Salvos: results_6_2_rank\\ranking_2018_Q1.csv e results_6_2_rank\\ranking_2018_Q1.png\n",
      "[GA-REG] geração 1/5\n",
      "[GA-REG] geração 2/5\n",
      "[GA-REG] geração 3/5\n",
      "[GA-REG] geração 4/5\n",
      "[GA-REG] geração 5/5\n",
      "[GA-REG] melhor RMSE: 0.12547052764823824\n",
      "[GA-REG] best_params: {'max_depth': 6, 'learning_rate': 0.07, 'subsample': 1.0, 'colsample_bytree': 0.7, 'min_child_weight': 1, 'gamma': 0.0}\n",
      "Salvos: results_6_2_rank\\ranking_2018_Q2.csv e results_6_2_rank\\ranking_2018_Q2.png\n",
      "[GA-REG] geração 1/5\n",
      "[GA-REG] geração 2/5\n",
      "[GA-REG] geração 3/5\n",
      "[GA-REG] geração 4/5\n",
      "[GA-REG] geração 5/5\n",
      "[GA-REG] melhor RMSE: 0.1272272542906026\n",
      "[GA-REG] best_params: {'max_depth': 6, 'learning_rate': 0.03, 'subsample': 0.9, 'colsample_bytree': 1.0, 'min_child_weight': 1, 'gamma': 0.01}\n",
      "Salvos: results_6_2_rank\\ranking_2018_Q3.csv e results_6_2_rank\\ranking_2018_Q3.png\n",
      "[GA-REG] geração 1/5\n",
      "[GA-REG] geração 2/5\n",
      "[GA-REG] geração 3/5\n",
      "[GA-REG] geração 4/5\n",
      "[GA-REG] geração 5/5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m2017\u001b[39m, \u001b[38;5;241m2018\u001b[39m, \u001b[38;5;241m2019\u001b[39m]:\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m q \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m]:\n\u001b[1;32m----> 4\u001b[0m         \u001b[43mrank_and_plot_quarter\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_ga\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConcluído.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[23], line 118\u001b[0m, in \u001b[0;36mrank_and_plot_quarter\u001b[1;34m(year, quarter, use_ga, save, show)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;66;03m# Hiperparâmetros (GA + CV Fig.2, ou defaults leves para depurar)\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_ga:\n\u001b[1;32m--> 118\u001b[0m     params \u001b[38;5;241m=\u001b[39m \u001b[43mga_optimize_xgb_reg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpop_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    120\u001b[0m     params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m5\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m0.05\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m0.8\u001b[39m,\n\u001b[0;32m    121\u001b[0m               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolsample_bytree\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m0.8\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin_child_weight\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m3\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgamma\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m0.05\u001b[39m}\n",
      "Cell \u001b[1;32mIn[23], line 88\u001b[0m, in \u001b[0;36mga_optimize_xgb_reg\u001b[1;34m(X_train, y_train, generations, pop_size, verbose)\u001b[0m\n\u001b[0;32m     85\u001b[0m     population \u001b[38;5;241m=\u001b[39m survivors \u001b[38;5;241m+\u001b[39m children\n\u001b[0;32m     87\u001b[0m \u001b[38;5;66;03m# Escolhe o melhor (menor RMSE)\u001b[39;00m\n\u001b[1;32m---> 88\u001b[0m final_scores \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mfitness\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpopulation\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     89\u001b[0m best_params  \u001b[38;5;241m=\u001b[39m population[\u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39margmin(final_scores))]\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n",
      "Cell \u001b[1;32mIn[23], line 88\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     85\u001b[0m     population \u001b[38;5;241m=\u001b[39m survivors \u001b[38;5;241m+\u001b[39m children\n\u001b[0;32m     87\u001b[0m \u001b[38;5;66;03m# Escolhe o melhor (menor RMSE)\u001b[39;00m\n\u001b[1;32m---> 88\u001b[0m final_scores \u001b[38;5;241m=\u001b[39m [\u001b[43mfitness\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m population]\n\u001b[0;32m     89\u001b[0m best_params  \u001b[38;5;241m=\u001b[39m population[\u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39margmin(final_scores))]\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n",
      "Cell \u001b[1;32mIn[23], line 55\u001b[0m, in \u001b[0;36mga_optimize_xgb_reg.<locals>.fitness\u001b[1;34m(params)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tr, va \u001b[38;5;129;01min\u001b[39;00m kf\u001b[38;5;241m.\u001b[39msplit(X_train):\n\u001b[0;32m     50\u001b[0m     model \u001b[38;5;241m=\u001b[39m XGBRegressor(\n\u001b[0;32m     51\u001b[0m         n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m,\n\u001b[0;32m     52\u001b[0m         objective\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreg:squarederror\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     53\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[0;32m     54\u001b[0m     )\n\u001b[1;32m---> 55\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m     pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_train[va])\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;66;03m# Versões antigas do sklearn não aceitam 'squared'; calculamos RMSE manualmente\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\thgcn\\anaconda3\\envs\\fin-ml\\Lib\\site-packages\\xgboost\\core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    728\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 729\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\thgcn\\anaconda3\\envs\\fin-ml\\Lib\\site-packages\\xgboost\\sklearn.py:1247\u001b[0m, in \u001b[0;36mXGBModel.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[0;32m   1244\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1245\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1247\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1248\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1249\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1250\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1251\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1258\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1261\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_evaluation_result(evals_result)\n\u001b[0;32m   1262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\thgcn\\anaconda3\\envs\\fin-ml\\Lib\\site-packages\\xgboost\\core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    728\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 729\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\thgcn\\anaconda3\\envs\\fin-ml\\Lib\\site-packages\\xgboost\\training.py:183\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 183\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\thgcn\\anaconda3\\envs\\fin-ml\\Lib\\site-packages\\xgboost\\core.py:2247\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   2243\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[0;32m   2245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2246\u001b[0m     _check_call(\n\u001b[1;32m-> 2247\u001b[0m         \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2248\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\n\u001b[0;32m   2249\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2250\u001b[0m     )\n\u001b[0;32m   2251\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2252\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Todos os trimestres 2017–2019, em sequência:\n",
    "for y in [2017, 2018, 2019]:\n",
    "    for q in [1,2,3,4]:\n",
    "        rank_and_plot_quarter(y, q, use_ga=True, save=True, show=False)\n",
    "print(\"Concluído.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (fin-ml)",
   "language": "python",
   "name": "fin-ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
