{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "190f68d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ee8530a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- Paths --------------------\n",
    "TRAIN_CSV = \"pead_preproc/train_processed.csv\"\n",
    "TEST_CSV  = \"pead_preproc/test_processed.csv\"\n",
    "\n",
    "OUT_DIR = \"results_6_1\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7eb39b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- Config --------------------\n",
    "\n",
    "TOP_K  = 5\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "TARGET = \"CAR_30D\"            # alvo para regressão\n",
    "EVENT_DATE_COL = \"EventTradeDate\"  # usado para partições/ano\n",
    "ID_COLS = [\"Ticker\", \"EventTradeDate\", \"AnnounceDate\", \"SectorName\", \"SectorID\", \"EstimationLen\", \"FundSource\", \"Data\", \"Empresa\" ]\n",
    "\n",
    "LEAK_PREFIX  = (\"CAR_\", \"AR_\", \"RET_\")   # não usar como feature\n",
    "# Se quiser banir mais colunas, pode adicionar aqui:\n",
    "BAN_COLS = set([TARGET])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "832bd39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATS = [\n",
    "\n",
    "    # ===== Fundamental – níveis MET =====\n",
    "    \"RL_MET\", \"LL_MET\", \"EBITDA_MET\",\n",
    "    \"Preco_Abertura_MET\", \"Preco_Fechamento_MET\",\n",
    "    \"LPA_MET\", \"ROA_MET\", \"ROE_MET\", \"MEB_MET\",\n",
    "    \"CRESC_RL_12M_MET\", \"CRESC_LL_12M_MET\", \"CRESC_EBITDA_12M_MET\",\n",
    "    \"CAPEX_MET\", \"FCO_MET\", \"FCF_MET\",\n",
    "    \"Divida_Liquida_MET\", \"PL_MET\", \"Divida_Bruta_MET\",\n",
    "    \"AT_MET\", \"DVA_Despesas_Fin_MET\",\n",
    "    \"PC_MET\", \"PNC_MET\", \"Outros_PC_MET\",\n",
    "    \"LUB_MET\",\n",
    "\n",
    "    # ===== Fundamental – variações Q (quarter-over-quarter) =====\n",
    "    \"RL_Q_Change\", \"LL_Q_Change\", \"EBITDA_Q_Change\",\n",
    "    \"Preco_Abertura_Q_Change\", \"Preco_Fechamento_Q_Change\",\n",
    "    \"LPA_Q_Change\", \"ROA_Q_Change\", \"ROE_Q_Change\", \"MEB_Q_Change\",\n",
    "    \"CRESC_RL_12M_Q_Change\", \"CRESC_LL_12M_Q_Change\", \"CRESC_EBITDA_12M_Q_Change\",\n",
    "    \"CAPEX_Q_Change\", \"FCO_Q_Change\", \"FCF_Q_Change\",\n",
    "    \"Divida_Liquida_Q_Change\", \"PL_Q_Change\", \"Divida_Bruta_Q_Change\",\n",
    "    \"AT_Q_Change\", \"DVA_Despesas_Fin_Q_Change\",\n",
    "    \"PC_Q_Change\", \"PNC_Q_Change\", \"Outros_PC_Q_Change\",\n",
    "    \"LUB_Q_Change\",\n",
    "\n",
    "    # ===== Fundamental – variações Y (year-over-year) =====\n",
    "    \"RL_Y_Change\", \"LL_Y_Change\", \"EBITDA_Y_Change\",\n",
    "    \"Preco_Abertura_Y_Change\", \"Preco_Fechamento_Y_Change\",\n",
    "    \"LPA_Y_Change\", \"ROA_Y_Change\", \"ROE_Y_Change\", \"MEB_Y_Change\",\n",
    "    \"CRESC_RL_12M_Y_Change\", \"CRESC_LL_12M_Y_Change\", \"CRESC_EBITDA_12M_Y_Change\",\n",
    "    \"CAPEX_Y_Change\", \"FCO_Y_Change\", \"FCF_Y_Change\",\n",
    "    \"Divida_Liquida_Y_Change\", \"PL_Y_Change\", \"Divida_Bruta_Y_Change\",\n",
    "    \"AT_Y_Change\", \"DVA_Despesas_Fin_Y_Change\",\n",
    "    \"PC_Y_Change\", \"PNC_Y_Change\", \"Outros_PC_Y_Change\",\n",
    "    \"LUB_Y_Change\",\n",
    "\n",
    "    # ===== EPS Surprise Features =====\n",
    "    \"EPS_EarningsSurprise\",\n",
    "    \"EPS_Earnings_Surprise_Backward_Diff\",\n",
    "    \"EPS_Earnings_Surprise_Backward_Ave_Diff\",\n",
    "\n",
    "    # ===== Momentum & Technical Indicators =====\n",
    "    \"MA5\", \"MA50\", \"MA200\",\n",
    "    \"RSI9\", \"RSI14\", \"RSI30\",\n",
    "    \"MA5_50\", \"MA5_200\", \"MA50_200\",\n",
    "    \"MOM_1M\", \"MOM_3M\", \"MOM_6M\", \"MOM_12M\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9faccb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de otimização GA simples\n",
    "# (exemplo realista mas leve para 100 runs)\n",
    "# ===============================\n",
    "\n",
    "import random\n",
    "\n",
    "def ga_optimize_xgb(X_train, y_train, generations=5, pop_size=10, verbose=True):\n",
    "    \"\"\"\n",
    "    GA + 5-fold CV para XGBoost\n",
    "    Corrigido para obedecer todos os limites do XGBoost.\n",
    "    Suporta 100 execuções sem quebrar.\n",
    "    \"\"\"\n",
    "\n",
    "    # --------------------------\n",
    "    # Espaço de busca (do paper)\n",
    "    # --------------------------\n",
    "    SEARCH_SPACE = {\n",
    "        \"max_depth\":        [3,4,5,6,7],\n",
    "        \"learning_rate\":    [0.01, 0.03, 0.05, 0.07, 0.1],\n",
    "        \"subsample\":        [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "        \"colsample_bytree\": [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "        \"min_child_weight\": [1,2,3,5,7],\n",
    "        \"gamma\":            [0, 0.01, 0.05, 0.1, 0.2],\n",
    "    }\n",
    "\n",
    "    def random_params():\n",
    "        return {k: np.random.choice(v) for k, v in SEARCH_SPACE.items()}\n",
    "\n",
    "    # --------------------------\n",
    "    # CV Fitness (igual ao paper)\n",
    "    # --------------------------\n",
    "    def fitness(params):\n",
    "        kf = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "        acc_list = []\n",
    "        for tr, va in kf.split(X_train):\n",
    "            model = XGBClassifier(\n",
    "                n_estimators=200,\n",
    "                objective=\"binary:logistic\",\n",
    "                eval_metric=\"logloss\",\n",
    "                **params\n",
    "            )\n",
    "            model.fit(X_train[tr], y_train[tr])\n",
    "            preds = model.predict(X_train[va])\n",
    "            acc_list.append(accuracy_score(y_train[va], preds))\n",
    "\n",
    "        return np.mean(acc_list)\n",
    "\n",
    "    # --------------------------\n",
    "    # Inicialização\n",
    "    # --------------------------\n",
    "    population = [random_params() for _ in range(pop_size)]\n",
    "\n",
    "    # --------------------------\n",
    "    # Evolução genética\n",
    "    # --------------------------\n",
    "    for gen in range(generations):\n",
    "        if verbose:\n",
    "            print(f\"    [GA] geração {gen+1}/{generations}\", flush=True)\n",
    "        \n",
    "        scores = [fitness(p) for p in population]\n",
    "\n",
    "        # Seleção — top 50%\n",
    "        ranked = sorted(zip(scores, population), key=lambda x: -x[0])\n",
    "        survivors = [p for _, p in ranked[:pop_size // 2]]\n",
    "\n",
    "        # Reprodução\n",
    "        children = []\n",
    "        while len(children) < pop_size - len(survivors):\n",
    "            p1, p2 = random.sample(survivors, 2)\n",
    "            child = {}\n",
    "\n",
    "            # Crossover seguro\n",
    "            for k in SEARCH_SPACE:\n",
    "                child[k] = p1[k] if random.random() < 0.5 else p2[k]\n",
    "\n",
    "            # Mutação segura\n",
    "            if np.random.rand() < 0.20:  # prob. maior para explorar\n",
    "                mut_key = np.random.choice(list(SEARCH_SPACE.keys()))\n",
    "                child[mut_key] = np.random.choice(SEARCH_SPACE[mut_key])\n",
    "\n",
    "            children.append(child)\n",
    "\n",
    "        population = survivors + children\n",
    "\n",
    "    # Melhor indivíduo final\n",
    "    final_scores = [fitness(p) for p in population]\n",
    "    best_params = population[int(np.argmax(final_scores))]\n",
    "\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55afb118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega os dados\n",
    "# ===============================\n",
    "\n",
    "df_train = pd.read_csv(TRAIN_CSV)\n",
    "df_test  = pd.read_csv(TEST_CSV)\n",
    "\n",
    "df = pd.concat([df_train, df_test], ignore_index=True)\n",
    "\n",
    "df[\"Year\"] = pd.to_datetime(df[\"EventTradeDate\"]).dt.year\n",
    "df[\"SectorName\"] = df[\"SectorName\"].astype(str)\n",
    "\n",
    "# target binário\n",
    "df[\"CAR_sign_bin\"] = (df[\"CAR_30D\"] > 0).astype(int)\n",
    "\n",
    "# anos do paper 6.1\n",
    "YEARS = [2017, 2018, 2019]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51a3e830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapeia f0,f1,... -> nome da feature (para get_score do XGBoost)\n",
    "fmap = {f\"f{i}\": feat for i, feat in enumerate(FEATS)}\n",
    "\n",
    "# para Tabela 6 (ALL stocks por ano)\n",
    "importance_counts_all = {y: defaultdict(int)   for y in YEARS}\n",
    "importance_sum_all    = {y: defaultdict(float) for y in YEARS}\n",
    "\n",
    "# para Tabelas 7–15 (por setor e ano)\n",
    "importance_counts_sector = {y: {} for y in YEARS}  # dict[year][sector] -> defaultdict(int)\n",
    "importance_sum_sector    = {y: {} for y in YEARS}  # dict[year][sector] -> defaultdict(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b06e07d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ANO 2017 ===\n",
      "    [GA] geração 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [GA] geração 2/5\n",
      "    [GA] geração 3/5\n",
      "    [GA] geração 4/5\n",
      "    [GA] geração 5/5\n",
      "  Run 1/100\n",
      "  Run 2/100\n",
      "  Run 3/100\n",
      "  Run 4/100\n",
      "  Run 5/100\n",
      "  Run 6/100\n",
      "  Run 7/100\n",
      "  Run 8/100\n",
      "  Run 9/100\n",
      "  Run 10/100\n",
      "  Run 11/100\n",
      "  Run 12/100\n",
      "  Run 13/100\n",
      "  Run 14/100\n",
      "  Run 15/100\n",
      "  Run 16/100\n",
      "  Run 17/100\n",
      "  Run 18/100\n",
      "  Run 19/100\n",
      "  Run 20/100\n",
      "  Run 21/100\n",
      "  Run 22/100\n",
      "  Run 23/100\n",
      "  Run 24/100\n",
      "  Run 25/100\n",
      "  Run 26/100\n",
      "  Run 27/100\n",
      "  Run 28/100\n",
      "  Run 29/100\n",
      "  Run 30/100\n",
      "  Run 31/100\n",
      "  Run 32/100\n",
      "  Run 33/100\n",
      "  Run 34/100\n",
      "  Run 35/100\n",
      "  Run 36/100\n",
      "  Run 37/100\n",
      "  Run 38/100\n",
      "  Run 39/100\n",
      "  Run 40/100\n",
      "  Run 41/100\n",
      "  Run 42/100\n",
      "  Run 43/100\n",
      "  Run 44/100\n",
      "  Run 45/100\n",
      "  Run 46/100\n",
      "  Run 47/100\n",
      "  Run 48/100\n",
      "  Run 49/100\n",
      "  Run 50/100\n",
      "  Run 51/100\n",
      "  Run 52/100\n",
      "  Run 53/100\n",
      "  Run 54/100\n",
      "  Run 55/100\n",
      "  Run 56/100\n",
      "  Run 57/100\n",
      "  Run 58/100\n",
      "  Run 59/100\n",
      "  Run 60/100\n",
      "  Run 61/100\n",
      "  Run 62/100\n",
      "  Run 63/100\n",
      "  Run 64/100\n",
      "  Run 65/100\n",
      "  Run 66/100\n",
      "  Run 67/100\n",
      "  Run 68/100\n",
      "  Run 69/100\n",
      "  Run 70/100\n",
      "  Run 71/100\n",
      "  Run 72/100\n",
      "  Run 73/100\n",
      "  Run 74/100\n",
      "  Run 75/100\n",
      "  Run 76/100\n",
      "  Run 77/100\n",
      "  Run 78/100\n",
      "  Run 79/100\n",
      "  Run 80/100\n",
      "  Run 81/100\n",
      "  Run 82/100\n",
      "  Run 83/100\n",
      "  Run 84/100\n",
      "  Run 85/100\n",
      "  Run 86/100\n",
      "  Run 87/100\n",
      "  Run 88/100\n",
      "  Run 89/100\n",
      "  Run 90/100\n",
      "  Run 91/100\n",
      "  Run 92/100\n",
      "  Run 93/100\n",
      "  Run 94/100\n",
      "  Run 95/100\n",
      "  Run 96/100\n",
      "  Run 97/100\n",
      "  Run 98/100\n",
      "  Run 99/100\n",
      "  Run 100/100\n",
      "\n",
      "=== ANO 2018 ===\n",
      "    [GA] geração 1/5\n",
      "    [GA] geração 2/5\n",
      "    [GA] geração 3/5\n",
      "    [GA] geração 4/5\n",
      "    [GA] geração 5/5\n",
      "  Run 1/100\n",
      "  Run 2/100\n",
      "  Run 3/100\n",
      "  Run 4/100\n",
      "  Run 5/100\n",
      "  Run 6/100\n",
      "  Run 7/100\n",
      "  Run 8/100\n",
      "  Run 9/100\n",
      "  Run 10/100\n",
      "  Run 11/100\n",
      "  Run 12/100\n",
      "  Run 13/100\n",
      "  Run 14/100\n",
      "  Run 15/100\n",
      "  Run 16/100\n",
      "  Run 17/100\n",
      "  Run 18/100\n",
      "  Run 19/100\n",
      "  Run 20/100\n",
      "  Run 21/100\n",
      "  Run 22/100\n",
      "  Run 23/100\n",
      "  Run 24/100\n",
      "  Run 25/100\n",
      "  Run 26/100\n",
      "  Run 27/100\n",
      "  Run 28/100\n",
      "  Run 29/100\n",
      "  Run 30/100\n",
      "  Run 31/100\n",
      "  Run 32/100\n",
      "  Run 33/100\n",
      "  Run 34/100\n",
      "  Run 35/100\n",
      "  Run 36/100\n",
      "  Run 37/100\n",
      "  Run 38/100\n",
      "  Run 39/100\n",
      "  Run 40/100\n",
      "  Run 41/100\n",
      "  Run 42/100\n",
      "  Run 43/100\n",
      "  Run 44/100\n",
      "  Run 45/100\n",
      "  Run 46/100\n",
      "  Run 47/100\n",
      "  Run 48/100\n",
      "  Run 49/100\n",
      "  Run 50/100\n",
      "  Run 51/100\n",
      "  Run 52/100\n",
      "  Run 53/100\n",
      "  Run 54/100\n",
      "  Run 55/100\n",
      "  Run 56/100\n",
      "  Run 57/100\n",
      "  Run 58/100\n",
      "  Run 59/100\n",
      "  Run 60/100\n",
      "  Run 61/100\n",
      "  Run 62/100\n",
      "  Run 63/100\n",
      "  Run 64/100\n",
      "  Run 65/100\n",
      "  Run 66/100\n",
      "  Run 67/100\n",
      "  Run 68/100\n",
      "  Run 69/100\n",
      "  Run 70/100\n",
      "  Run 71/100\n",
      "  Run 72/100\n",
      "  Run 73/100\n",
      "  Run 74/100\n",
      "  Run 75/100\n",
      "  Run 76/100\n",
      "  Run 77/100\n",
      "  Run 78/100\n",
      "  Run 79/100\n",
      "  Run 80/100\n",
      "  Run 81/100\n",
      "  Run 82/100\n",
      "  Run 83/100\n",
      "  Run 84/100\n",
      "  Run 85/100\n",
      "  Run 86/100\n",
      "  Run 87/100\n",
      "  Run 88/100\n",
      "  Run 89/100\n",
      "  Run 90/100\n",
      "  Run 91/100\n",
      "  Run 92/100\n",
      "  Run 93/100\n",
      "  Run 94/100\n",
      "  Run 95/100\n",
      "  Run 96/100\n",
      "  Run 97/100\n",
      "  Run 98/100\n",
      "  Run 99/100\n",
      "  Run 100/100\n",
      "\n",
      "=== ANO 2019 ===\n",
      "    [GA] geração 1/5\n",
      "    [GA] geração 2/5\n",
      "    [GA] geração 3/5\n",
      "    [GA] geração 4/5\n",
      "    [GA] geração 5/5\n",
      "  Run 1/100\n",
      "  Run 2/100\n",
      "  Run 3/100\n",
      "  Run 4/100\n",
      "  Run 5/100\n",
      "  Run 6/100\n",
      "  Run 7/100\n",
      "  Run 8/100\n",
      "  Run 9/100\n",
      "  Run 10/100\n",
      "  Run 11/100\n",
      "  Run 12/100\n",
      "  Run 13/100\n",
      "  Run 14/100\n",
      "  Run 15/100\n",
      "  Run 16/100\n",
      "  Run 17/100\n",
      "  Run 18/100\n",
      "  Run 19/100\n",
      "  Run 20/100\n",
      "  Run 21/100\n",
      "  Run 22/100\n",
      "  Run 23/100\n",
      "  Run 24/100\n",
      "  Run 25/100\n",
      "  Run 26/100\n",
      "  Run 27/100\n",
      "  Run 28/100\n",
      "  Run 29/100\n",
      "  Run 30/100\n",
      "  Run 31/100\n",
      "  Run 32/100\n",
      "  Run 33/100\n",
      "  Run 34/100\n",
      "  Run 35/100\n",
      "  Run 36/100\n",
      "  Run 37/100\n",
      "  Run 38/100\n",
      "  Run 39/100\n",
      "  Run 40/100\n",
      "  Run 41/100\n",
      "  Run 42/100\n",
      "  Run 43/100\n",
      "  Run 44/100\n",
      "  Run 45/100\n",
      "  Run 46/100\n",
      "  Run 47/100\n",
      "  Run 48/100\n",
      "  Run 49/100\n",
      "  Run 50/100\n",
      "  Run 51/100\n",
      "  Run 52/100\n",
      "  Run 53/100\n",
      "  Run 54/100\n",
      "  Run 55/100\n",
      "  Run 56/100\n",
      "  Run 57/100\n",
      "  Run 58/100\n",
      "  Run 59/100\n",
      "  Run 60/100\n",
      "  Run 61/100\n",
      "  Run 62/100\n",
      "  Run 63/100\n",
      "  Run 64/100\n",
      "  Run 65/100\n",
      "  Run 66/100\n",
      "  Run 67/100\n",
      "  Run 68/100\n",
      "  Run 69/100\n",
      "  Run 70/100\n",
      "  Run 71/100\n",
      "  Run 72/100\n",
      "  Run 73/100\n",
      "  Run 74/100\n",
      "  Run 75/100\n",
      "  Run 76/100\n",
      "  Run 77/100\n",
      "  Run 78/100\n",
      "  Run 79/100\n",
      "  Run 80/100\n",
      "  Run 81/100\n",
      "  Run 82/100\n",
      "  Run 83/100\n",
      "  Run 84/100\n",
      "  Run 85/100\n",
      "  Run 86/100\n",
      "  Run 87/100\n",
      "  Run 88/100\n",
      "  Run 89/100\n",
      "  Run 90/100\n",
      "  Run 91/100\n",
      "  Run 92/100\n",
      "  Run 93/100\n",
      "  Run 94/100\n",
      "  Run 95/100\n",
      "  Run 96/100\n",
      "  Run 97/100\n",
      "  Run 98/100\n",
      "  Run 99/100\n",
      "  Run 100/100\n"
     ]
    }
   ],
   "source": [
    "# LOOP PRINCIPAL – 100 RUNS\n",
    "# ===============================\n",
    "\n",
    "results_year = {y: [] for y in YEARS}\n",
    "results_sector = {y: {} for y in YEARS}\n",
    "\n",
    "for year in YEARS:\n",
    "\n",
    "    print(f\"\\n=== ANO {year} ===\")\n",
    "\n",
    "    df_train_y = df[df[\"Year\"] < year].copy()\n",
    "    df_test_y  = df[df[\"Year\"] == year].copy()\n",
    "\n",
    "    X_train = df_train_y[FEATS].values\n",
    "    y_train = df_train_y[\"CAR_sign_bin\"].values\n",
    "\n",
    "    X_test  = df_test_y[FEATS].values\n",
    "    y_test  = df_test_y[\"CAR_sign_bin\"].values\n",
    "    sector_test = df_test_y[\"SectorName\"].values\n",
    "\n",
    "    # ----------- 100 RUNS -------------\n",
    "\n",
    "    best_params_year = ga_optimize_xgb(X_train, y_train, generations=5, pop_size=10, verbose=True)\n",
    "    for run in range(100):\n",
    "        print(f\"  Run {run+1}/100\", flush=True)\n",
    "        model = XGBClassifier(\n",
    "        n_estimators=200,\n",
    "        objective=\"binary:logistic\",\n",
    "        eval_metric=\"logloss\",\n",
    "        **best_params_year)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        preds = model.predict(X_test)\n",
    "        acc = accuracy_score(y_test, preds)\n",
    "\n",
    "        results_year[year].append(acc)\n",
    "\n",
    "        # Por setor\n",
    "        for s in np.unique(sector_test):\n",
    "            mask = (sector_test == s)\n",
    "            if mask.sum() > 0:\n",
    "                acc_s = accuracy_score(y_test[mask], preds[mask])\n",
    "                results_sector[year].setdefault(s, []).append(acc_s)\n",
    "    \n",
    "        # ---------- IMPORTÂNCIAS PARA TABELAS 6–15 ----------\n",
    "        booster = model.get_booster()\n",
    "        raw_scores = booster.get_score(importance_type=\"gain\")  # ganho\n",
    "\n",
    "        # converte f0,f1,... -> nome da feature\n",
    "        scores_named = {}\n",
    "        for k, v in raw_scores.items():\n",
    "            feat_name = fmap.get(k, k)\n",
    "            scores_named[feat_name] = float(v)\n",
    "\n",
    "        if not scores_named:\n",
    "            continue\n",
    "\n",
    "        # normaliza importâncias para somarem 1 neste run\n",
    "        total_gain = sum(scores_named.values())\n",
    "        if total_gain <= 0:\n",
    "            continue\n",
    "        for f in scores_named:\n",
    "            scores_named[f] /= total_gain\n",
    "\n",
    "        # TOP_K para o grupo \"all stocks\" (Tabela 6)\n",
    "        top_feats_all = sorted(scores_named.items(), key=lambda x: -x[1])[:TOP_K]\n",
    "        for feat, imp_norm in top_feats_all:\n",
    "            importance_counts_all[year][feat] += 1\n",
    "            importance_sum_all[year][feat]    += imp_norm\n",
    "\n",
    "        # TOP_K por setor (Tabelas 7–15)\n",
    "        # aqui usamos os MESMOS scores_named para todos os setores,\n",
    "        # pois o modelo é global; o paper treina modelos por grupo,\n",
    "        # mas esta é a aproximação mais leve.\n",
    "        sectors_in_year = np.unique(sector_test)\n",
    "        for s in sectors_in_year:\n",
    "            if s not in importance_counts_sector[year]:\n",
    "                importance_counts_sector[year][s] = defaultdict(int)\n",
    "                importance_sum_sector[year][s]    = defaultdict(float)\n",
    "\n",
    "            top_feats_sec = top_feats_all  # mesma ordem do global\n",
    "            for feat, imp_norm in top_feats_sec:\n",
    "                importance_counts_sector[year][s][feat] += 1\n",
    "                importance_sum_sector[year][s][feat]    += imp_norm    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61af10ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados salvos em: results_6_1\n"
     ]
    }
   ],
   "source": [
    "# Salvar resultados\n",
    "# ===============================\n",
    "\n",
    "# Média por ano\n",
    "df_year = pd.DataFrame({\n",
    "    \"Year\": YEARS,\n",
    "    \"Accuracy_mean\": [np.mean(results_year[y]) for y in YEARS],\n",
    "    \"Accuracy_std\": [np.std(results_year[y]) for y in YEARS]\n",
    "})\n",
    "df_year.to_csv(os.path.join(OUT_DIR, \"accuracy_yearly.csv\"), index=False)\n",
    "\n",
    "\n",
    "# Média por setor por ano\n",
    "rows = []\n",
    "for y in YEARS:\n",
    "    for s, vals in results_sector[y].items():\n",
    "        rows.append({\n",
    "            \"Year\": y,\n",
    "            \"SectorName\": s,\n",
    "            \"Accuracy_mean\": np.mean(vals),\n",
    "            \"Accuracy_std\": np.std(vals)\n",
    "        })\n",
    "df_sector = pd.DataFrame(rows)\n",
    "df_sector.to_csv(os.path.join(OUT_DIR, \"accuracy_sector_yearly.csv\"), index=False)\n",
    "\n",
    "print(\"\\nResultados salvos em:\", OUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc7218cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_RUNS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82e8ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabela 6 salva em: results_6_1\\table6_all_stocks_top5.csv\n",
      "Tabela setor Bens Industriais ano 2017 salva em: results_6_1\\table_sector_Bens_Industriais_2017.csv\n",
      "Tabela setor Consumo Cíclico ano 2017 salva em: results_6_1\\table_sector_Consumo_Cíclico_2017.csv\n",
      "Tabela setor Consumo Não Cíclico ano 2017 salva em: results_6_1\\table_sector_Consumo_Não_Cíclico_2017.csv\n",
      "Tabela setor Financeiro e Outros ano 2017 salva em: results_6_1\\table_sector_Financeiro_e_Outros_2017.csv\n",
      "Tabela setor Materiais Básicos ano 2017 salva em: results_6_1\\table_sector_Materiais_Básicos_2017.csv\n",
      "Tabela setor Petróleo, Gás e Biocombustíveis ano 2017 salva em: results_6_1\\table_sector_Petróleo,_Gás_e_Biocombustíveis_2017.csv\n",
      "Tabela setor Saúde ano 2017 salva em: results_6_1\\table_sector_Saúde_2017.csv\n",
      "Tabela setor Tecnologia da Informação ano 2017 salva em: results_6_1\\table_sector_Tecnologia_da_Informação_2017.csv\n",
      "Tabela setor Telecomunicações ano 2017 salva em: results_6_1\\table_sector_Telecomunicações_2017.csv\n",
      "Tabela setor Utilidade Pública ano 2017 salva em: results_6_1\\table_sector_Utilidade_Pública_2017.csv\n",
      "Tabela setor Bens Industriais ano 2018 salva em: results_6_1\\table_sector_Bens_Industriais_2018.csv\n",
      "Tabela setor Consumo Cíclico ano 2018 salva em: results_6_1\\table_sector_Consumo_Cíclico_2018.csv\n",
      "Tabela setor Consumo Não Cíclico ano 2018 salva em: results_6_1\\table_sector_Consumo_Não_Cíclico_2018.csv\n",
      "Tabela setor Financeiro e Outros ano 2018 salva em: results_6_1\\table_sector_Financeiro_e_Outros_2018.csv\n",
      "Tabela setor Materiais Básicos ano 2018 salva em: results_6_1\\table_sector_Materiais_Básicos_2018.csv\n",
      "Tabela setor Petróleo, Gás e Biocombustíveis ano 2018 salva em: results_6_1\\table_sector_Petróleo,_Gás_e_Biocombustíveis_2018.csv\n",
      "Tabela setor Saúde ano 2018 salva em: results_6_1\\table_sector_Saúde_2018.csv\n",
      "Tabela setor Tecnologia da Informação ano 2018 salva em: results_6_1\\table_sector_Tecnologia_da_Informação_2018.csv\n",
      "Tabela setor Telecomunicações ano 2018 salva em: results_6_1\\table_sector_Telecomunicações_2018.csv\n",
      "Tabela setor Utilidade Pública ano 2018 salva em: results_6_1\\table_sector_Utilidade_Pública_2018.csv\n",
      "Tabela setor Bens Industriais ano 2019 salva em: results_6_1\\table_sector_Bens_Industriais_2019.csv\n",
      "Tabela setor Consumo Cíclico ano 2019 salva em: results_6_1\\table_sector_Consumo_Cíclico_2019.csv\n",
      "Tabela setor Consumo Não Cíclico ano 2019 salva em: results_6_1\\table_sector_Consumo_Não_Cíclico_2019.csv\n",
      "Tabela setor Financeiro e Outros ano 2019 salva em: results_6_1\\table_sector_Financeiro_e_Outros_2019.csv\n",
      "Tabela setor Materiais Básicos ano 2019 salva em: results_6_1\\table_sector_Materiais_Básicos_2019.csv\n",
      "Tabela setor Petróleo, Gás e Biocombustíveis ano 2019 salva em: results_6_1\\table_sector_Petróleo,_Gás_e_Biocombustíveis_2019.csv\n",
      "Tabela setor Saúde ano 2019 salva em: results_6_1\\table_sector_Saúde_2019.csv\n",
      "Tabela setor Tecnologia da Informação ano 2019 salva em: results_6_1\\table_sector_Tecnologia_da_Informação_2019.csv\n",
      "Tabela setor Telecomunicações ano 2019 salva em: results_6_1\\table_sector_Telecomunicações_2019.csv\n",
      "Tabela setor Utilidade Pública ano 2019 salva em: results_6_1\\table_sector_Utilidade_Pública_2019.csv\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'TABLES_6_15_TEXT' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 69\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# (opcional) salva o texto explicativo em um .txt\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(OUT_DIR, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtables_6_15_description.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m---> 69\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(\u001b[43mTABLES_6_15_TEXT\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'TABLES_6_15_TEXT' is not defined"
     ]
    }
   ],
   "source": [
    "# ---------------------- TABELA 6: ALL STOCKS (por ano) ----------------------\n",
    "rows_all = []\n",
    "\n",
    "for year in YEARS:\n",
    "    for feat, count in importance_counts_all[year].items():\n",
    "        mean_imp = importance_sum_all[year][feat] / float(N_RUNS)\n",
    "        rows_all.append({\n",
    "            \"Year\": year,\n",
    "            \"Feature\": feat,\n",
    "            \"OccurrenceCount\": count,\n",
    "            \"NormalizedImportanceMean\": mean_imp\n",
    "        })\n",
    "\n",
    "df_all_imp = pd.DataFrame(rows_all)\n",
    "\n",
    "# ordena dentro de cada ano\n",
    "df_all_imp = df_all_imp.sort_values(\n",
    "    [\"Year\", \"OccurrenceCount\", \"NormalizedImportanceMean\"],\n",
    "    ascending=[True, False, False]\n",
    ")\n",
    "\n",
    "# pega TOP 5 de cada ano (F1..F5)\n",
    "table6_parts = []\n",
    "for year in YEARS:\n",
    "    sub = df_all_imp[df_all_imp[\"Year\"] == year].head(5).copy()\n",
    "    # adiciona labels F1..F5\n",
    "    sub[\"F_label\"] = [f\"F{i}\" for i in range(1, len(sub)+1)]\n",
    "    table6_parts.append(sub)\n",
    "\n",
    "table6 = pd.concat(table6_parts, ignore_index=True)\n",
    "table6_path = os.path.join(OUT_DIR, \"table6_all_stocks_top5.csv\")\n",
    "table6.to_csv(table6_path, index=False)\n",
    "print(\"Tabela 6 salva em:\", table6_path)\n",
    "\n",
    "\n",
    "# ---------------------- TABELAS 7–15: POR SETOR ----------------------\n",
    "# cada setor vira uma tabela separada (top 5 por ano)\n",
    "for year in YEARS:\n",
    "    for sector, counts_dict in importance_counts_sector[year].items():\n",
    "        rows_sec = []\n",
    "        for feat, count in counts_dict.items():\n",
    "            mean_imp = importance_sum_sector[year][sector][feat] / float(N_RUNS)\n",
    "            rows_sec.append({\n",
    "                \"Year\": year,\n",
    "                \"SectorName\": sector,\n",
    "                \"Feature\": feat,\n",
    "                \"OccurrenceCount\": count,\n",
    "                \"NormalizedImportanceMean\": mean_imp\n",
    "            })\n",
    "        if not rows_sec:\n",
    "            continue\n",
    "\n",
    "        df_sec = pd.DataFrame(rows_sec).sort_values(\n",
    "            [\"OccurrenceCount\", \"NormalizedImportanceMean\"],\n",
    "            ascending=[False, False]\n",
    "        ).head(5)  # top 5 do setor naquele ano\n",
    "        df_sec[\"F_label\"] = [f\"F{i}\" for i in range(1, len(df_sec)+1)]\n",
    "\n",
    "        # nome de arquivo tipo: table_sector_<nome>_<ano>.csv\n",
    "        safe_sector = sector.replace(\" \", \"_\").replace(\"/\", \"_\")\n",
    "        fname = f\"table_sector_{safe_sector}_{year}.csv\"\n",
    "        fpath = os.path.join(OUT_DIR, fname)\n",
    "        df_sec.to_csv(fpath, index=False)\n",
    "        print(f\"Tabela setor {sector} ano {year} salva em:\", fpath)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (fin-ml)",
   "language": "python",
   "name": "fin-ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
